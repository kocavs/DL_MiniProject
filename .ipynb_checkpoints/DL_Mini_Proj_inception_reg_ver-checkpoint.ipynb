{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cgn58bGLA7l"
   },
   "source": [
    "# ResNet For CIFAR0-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzleoGvIa3JV",
    "outputId": "3538b717-fc51-4f8f-a090-33bba3da645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "[Errno 2] No such file or directory: '/content/drive/My Drive/DL_Mini_Proj'\n",
      "/content\n",
      "checkpoint  data  drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd /content/drive/My\\ Drive/DL_Mini_Proj\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "enCe4Ish2n47"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "#import renet\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as data\n",
    "from renet import ResNet18\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgqUa4LeK3Tr"
   },
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "13PaS06K0N3g"
   },
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_planes, out_planes,\n",
    "            kernel_size=kernel_size, stride=stride,\n",
    "            padding=padding, bias=False\n",
    "        ) # verify bias false\n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            out_planes,\n",
    "            eps=0.001, # value found in tensorflow\n",
    "            momentum=0.1, # default pytorch value\n",
    "            affine=True\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        \n",
    "        branch_out_channels = out_channels // 4\n",
    "        print(out_channels)\n",
    "        \n",
    "        self.branch0 = BasicConv2d(in_channels, branch_out_channels, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, branch_out_channels, kernel_size=1, stride=1),\n",
    "            BasicConv2d(branch_out_channels, branch_out_channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, branch_out_channels, kernel_size=1, stride=1),\n",
    "            BasicConv2d(branch_out_channels, branch_out_channels, kernel_size=1, stride=1),\n",
    "            BasicConv2d(branch_out_channels, branch_out_channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(3 * branch_out_channels, self.expansion*out_channels,\n",
    "                                kernel_size=1, stride=1, bias=False)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != self.expansion*out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*out_channels,\n",
    "                          kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        \n",
    "#         print(f\"x0 shape: {x0.shape}\")\n",
    "#         print(f\"x1 shape: {x1.shape}\")\n",
    "#         print(f\"x2 shape: {x2.shape}\")\n",
    "        \n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        out = self.conv2d(out)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        print(f\"out shape: {out.shape}\")\n",
    "        return out\n",
    "\n",
    "class InceptionResNet(nn.Module):\n",
    "    def __init__(self,  block, num_blocks, num_classes=10):\n",
    "        super(InceptionResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = BasicConv2d(3, 64, kernel_size=3, stride=2)   \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes) # ochange\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        print(f\"final out shape: {out.shape}\")\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the Inception-ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final out shape: torch.Size([2, 512])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "summary(ResNet18().to(device), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "JZ5l09322n6z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "256\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = InceptionResNet(InceptionModule, [1, 1, 1, 1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99yZ7-kNwN9",
    "outputId": "abe41fa8-cdab-40c4-eaf4-a2748c03bc46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape: torch.Size([2, 64, 15, 15])\n",
      "out shape: torch.Size([2, 128, 15, 15])\n",
      "out shape: torch.Size([2, 256, 15, 15])\n",
      "out shape: torch.Size([2, 512, 15, 15])\n",
      "final out shape: torch.Size([2, 4608])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x4608 and 512x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[102], line 104\u001b[0m, in \u001b[0;36mInceptionResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal out shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x4608 and 512x10)"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1F2LXoFL5K8"
   },
   "source": [
    "Construction Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwDtf6ypL-E9"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TneJZzB8Jmqs"
   },
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "  \"\"\"Randomly mask out one or more patches from an image.\n",
    "  Args:\n",
    "      n_holes (int): Number of patches to cut out of each image.\n",
    "      length (int): The length (in pixels) of each square patch.\n",
    "  \"\"\"\n",
    "  def __init__(self, n_holes, length):\n",
    "      self.n_holes = n_holes\n",
    "      self.length = length\n",
    "\n",
    "  def __call__(self, img):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "          img (Tensor): Tensor image of size (C, H, W).\n",
    "      Returns:\n",
    "          Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "      \"\"\"\n",
    "      h = img.size(1)\n",
    "      w = img.size(2)\n",
    "\n",
    "      mask = np.ones((h, w), np.float32)\n",
    "\n",
    "      for n in range(self.n_holes):\n",
    "          y = np.random.randint(h)\n",
    "          x = np.random.randint(w)\n",
    "\n",
    "          y1 = np.clip(y - self.length // 2, 0, h)\n",
    "          y2 = np.clip(y + self.length // 2, 0, h)\n",
    "          x1 = np.clip(x - self.length // 2, 0, w)\n",
    "          x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "          mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "      mask = torch.from_numpy(mask)\n",
    "      mask = mask.expand_as(img)\n",
    "      img = img * mask\n",
    "\n",
    "      return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DTMZC3WJmwF"
   },
   "outputs": [],
   "source": [
    "def load_CIFAR10(batch_size, train_ratio):\n",
    "\n",
    "  ROOT = './data'\n",
    "  trainset = torchvision.datasets.CIFAR10(\n",
    "      root = ROOT,\n",
    "      train = True, \n",
    "      download = True\n",
    "  )\n",
    "\n",
    "  # Compute means and standard deviations\n",
    "  means = trainset.data.mean(axis=(0,1,2)) / 255\n",
    "  stds = trainset.data.std(axis=(0,1,2)) / 255\n",
    "  #print(means, stds)\n",
    "\n",
    "  # Preprocess setting\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=means, std=stds),\n",
    "      Cutout(n_holes=1, length=16)\n",
    "  ])\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=means, std=stds)\n",
    "  ])\n",
    "\n",
    "  # Load the dataset\n",
    "  trainset = torchvision.datasets.CIFAR10(\n",
    "      root = ROOT, \n",
    "      train = True, \n",
    "      download = True, \n",
    "      transform = transform_train\n",
    "  )\n",
    "  testset = torchvision.datasets.CIFAR10(\n",
    "      root = ROOT, \n",
    "      train = False, \n",
    "      download = True, \n",
    "      transform = transform_test\n",
    "  )\n",
    "\n",
    "  train_iterator = data.DataLoader(trainset, batch_size)\n",
    "  test_iterator = data.DataLoader(testset, batch_size)\n",
    "\n",
    "  return train_iterator, test_iterator\n",
    "  \"\"\"\n",
    "  # Split trainset for validset\n",
    "  n_train = int(len(trainset) * train_ratio)\n",
    "  n_valid = len(trainset) - n_train\n",
    "  train_dataset, valid_dataset = data.random_split(trainset, [n_train, n_valid])\n",
    "  \n",
    "  # Build dataloader\n",
    "  train_iterator = data.DataLoader(train_dataset, batch_size)\n",
    "  valid_iterator = data.DataLoader(valid_dataset, batch_size)\n",
    "  test_iterator = data.DataLoader(testset, batch_size)\n",
    "\n",
    "  return train_iterator, valid_iterator, test_iterator\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21PibWhZJ6da",
    "outputId": "1eec05f0-d230-4423-8b60-75094d2c3d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# trainloader, validloader, testloader = load_CIFAR10(batch_size=16, train_ratio=1)\n",
    "trainloader, testloader = load_CIFAR10(batch_size=16, train_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "YcJteBmC2n8b",
    "outputId": "066729ed-3c40-405e-ef0f-a45f00fe1fce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ntransform_train = transforms.Compose([\\n    transforms.RandomCrop(32, padding=4),\\n    transforms.RandomHorizontalFlip(),\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n\\ntransform_test = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "4HFVdimn2n-O",
    "outputId": "a077aeac-74fa-4a86-e92c-ae83670d0aec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\ntrainset = torchvision.datasets.CIFAR10(\\n    root='./data', train=True, download=True, transform=transform_train) # change transform in future\\ntrainloader = torch.utils.data.DataLoader(\\n    trainset, batch_size=128, shuffle=True, num_workers=2)\\n\\ntestset = torchvision.datasets.CIFAR10(\\n    root='./data', train=False, download=True, transform=transform_test) # change transform in future\\ntestloader = torch.utils.data.DataLoader(\\n    testset, batch_size=100, shuffle=False, num_workers=2)\\n\\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\\n           'dog', 'frog', 'horse', 'ship', 'truck')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train) # change transform in future\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test) # change transform in future\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6RvRO3e6Rjp"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)#,weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbBSkXWE2n_7"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(\"Train Set Loss:\",train_loss/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxH7SkJJ2oBp"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "    print('Test Set Accuracy:',acc)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzs360FC2oKB",
    "outputId": "3aa77317-85d2-4309-c6b9-841d5d10216f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Set Loss: 0.12435709532499313\n",
      "Saving..\n",
      "Test Set Accuracy: 40.17\n",
      "\n",
      "Epoch: 1\n",
      "Train Set Loss: 0.10413713613629341\n",
      "Saving..\n",
      "Test Set Accuracy: 46.68\n",
      "\n",
      "Epoch: 2\n",
      "Train Set Loss: 0.09501234260678292\n",
      "Saving..\n",
      "Test Set Accuracy: 56.04\n",
      "\n",
      "Epoch: 3\n",
      "Train Set Loss: 0.08676004169225693\n",
      "Saving..\n",
      "Test Set Accuracy: 60.75\n",
      "\n",
      "Epoch: 4\n",
      "Train Set Loss: 0.08002455587863923\n",
      "Saving..\n",
      "Test Set Accuracy: 64.44\n",
      "\n",
      "Epoch: 5\n",
      "Train Set Loss: 0.07480791354775429\n",
      "Saving..\n",
      "Test Set Accuracy: 67.1\n",
      "\n",
      "Epoch: 6\n",
      "Train Set Loss: 0.07053399376451969\n",
      "Saving..\n",
      "Test Set Accuracy: 67.18\n",
      "\n",
      "Epoch: 7\n",
      "Train Set Loss: 0.0674082960832119\n",
      "Saving..\n",
      "Test Set Accuracy: 70.38\n",
      "\n",
      "Epoch: 8\n",
      "Train Set Loss: 0.06464856996834278\n",
      "Saving..\n",
      "Test Set Accuracy: 70.74\n",
      "\n",
      "Epoch: 9\n",
      "Train Set Loss: 0.06277236208796501\n",
      "Saving..\n",
      "Test Set Accuracy: 73.16\n",
      "\n",
      "Epoch: 10\n",
      "Train Set Loss: 0.06034281284093857\n",
      "Saving..\n",
      "Test Set Accuracy: 74.38\n",
      "\n",
      "Epoch: 11\n",
      "Train Set Loss: 0.05876245109558106\n",
      "Test Set Accuracy: 73.43\n",
      "\n",
      "Epoch: 12\n",
      "Train Set Loss: 0.057294746780395506\n",
      "Saving..\n",
      "Test Set Accuracy: 75.5\n",
      "\n",
      "Epoch: 13\n",
      "Train Set Loss: 0.0558021182101965\n",
      "Saving..\n",
      "Test Set Accuracy: 76.74\n",
      "\n",
      "Epoch: 14\n",
      "Train Set Loss: 0.05441540223121643\n",
      "Saving..\n",
      "Test Set Accuracy: 77.59\n",
      "\n",
      "Epoch: 15\n",
      "Train Set Loss: 0.05315229023814201\n",
      "Saving..\n",
      "Test Set Accuracy: 78.76\n",
      "\n",
      "Epoch: 16\n",
      "Train Set Loss: 0.05167149598568678\n",
      "Test Set Accuracy: 78.43\n",
      "\n",
      "Epoch: 17\n",
      "Train Set Loss: 0.05096915660917759\n",
      "Test Set Accuracy: 77.36\n",
      "\n",
      "Epoch: 18\n",
      "Train Set Loss: 0.049658230416923764\n",
      "Saving..\n",
      "Test Set Accuracy: 79.8\n",
      "\n",
      "Epoch: 19\n",
      "Train Set Loss: 0.04893088031411171\n",
      "Test Set Accuracy: 79.56\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+20):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XS9hEnaR0M2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for g in optimizer.param_groups:\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    g['lr'] = 0.001\n",
    "\"\"\"\n",
    "state = {\n",
    "      'net': model.state_dict()\n",
    "}\n",
    "if not os.path.isdir('checkpoint'):\n",
    "  os.mkdir('checkpoint')\n",
    "torch.save(state, './checkpoint/20Epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43wfxq1E1Xy9"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulxHcGSzRFwn",
    "outputId": "825c43ff-1784-4153-819e-ccd7744f93e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20\n",
      "Train Set Loss: 0.06111984935224056\n",
      "Test Set Accuracy: 76.53\n",
      "\n",
      "Epoch: 21\n",
      "Train Set Loss: 0.056872786796987054\n",
      "Test Set Accuracy: 77.37\n",
      "\n",
      "Epoch: 22\n",
      "Train Set Loss: 0.054467707093656066\n",
      "Test Set Accuracy: 78.47\n",
      "\n",
      "Epoch: 23\n",
      "Train Set Loss: 0.052736565395891666\n",
      "Test Set Accuracy: 79.78\n",
      "\n",
      "Epoch: 24\n",
      "Train Set Loss: 0.05089716591179371\n",
      "Saving..\n",
      "Test Set Accuracy: 79.98\n",
      "\n",
      "Epoch: 25\n",
      "Train Set Loss: 0.04973517975986004\n",
      "Saving..\n",
      "Test Set Accuracy: 80.31\n",
      "\n",
      "Epoch: 26\n",
      "Train Set Loss: 0.048367037560641764\n",
      "Saving..\n",
      "Test Set Accuracy: 80.35\n",
      "\n",
      "Epoch: 27\n",
      "Train Set Loss: 0.047496571877896784\n",
      "Saving..\n",
      "Test Set Accuracy: 81.09\n",
      "\n",
      "Epoch: 28\n",
      "Train Set Loss: 0.04673378049641848\n",
      "Saving..\n",
      "Test Set Accuracy: 81.87\n",
      "\n",
      "Epoch: 29\n",
      "Train Set Loss: 0.04588644198894501\n",
      "Test Set Accuracy: 81.37\n",
      "\n",
      "Epoch: 30\n",
      "Train Set Loss: 0.04482184986442327\n",
      "Test Set Accuracy: 81.79\n",
      "\n",
      "Epoch: 31\n",
      "Train Set Loss: 0.04400566786378622\n",
      "Saving..\n",
      "Test Set Accuracy: 83.04\n",
      "\n",
      "Epoch: 32\n",
      "Train Set Loss: 0.04339637280225754\n",
      "Test Set Accuracy: 83.0\n",
      "\n",
      "Epoch: 33\n",
      "Train Set Loss: 0.04295982111155987\n",
      "Test Set Accuracy: 82.9\n",
      "\n",
      "Epoch: 34\n",
      "Train Set Loss: 0.04221132900506258\n",
      "Saving..\n",
      "Test Set Accuracy: 83.48\n",
      "\n",
      "Epoch: 35\n",
      "Train Set Loss: 0.04187333113223314\n",
      "Saving..\n",
      "Test Set Accuracy: 83.66\n",
      "\n",
      "Epoch: 36\n",
      "Train Set Loss: 0.040972914422899485\n",
      "Test Set Accuracy: 83.16\n",
      "\n",
      "Epoch: 37\n",
      "Train Set Loss: 0.04076682301700115\n",
      "Saving..\n",
      "Test Set Accuracy: 83.74\n",
      "\n",
      "Epoch: 38\n",
      "Train Set Loss: 0.03991217172145844\n",
      "Saving..\n",
      "Test Set Accuracy: 84.29\n",
      "\n",
      "Epoch: 39\n",
      "Train Set Loss: 0.039652029202282425\n",
      "Saving..\n",
      "Test Set Accuracy: 84.73\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 20  \n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+20):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AFmB7xGRF6S",
    "outputId": "84197420-704a-4a33-ec07-119a2cc6e6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 40\n",
      "Train Set Loss: 0.03933024534359574\n",
      "Test Set Accuracy: 84.0\n",
      "\n",
      "Epoch: 41\n",
      "Train Set Loss: 0.03863885339826346\n",
      "Test Set Accuracy: 83.97\n",
      "\n",
      "Epoch: 42\n",
      "Train Set Loss: 0.038449449110776183\n",
      "Saving..\n",
      "Test Set Accuracy: 84.91\n",
      "\n",
      "Epoch: 43\n",
      "Train Set Loss: 0.03798370545908809\n",
      "Test Set Accuracy: 84.66\n",
      "\n",
      "Epoch: 44\n",
      "Train Set Loss: 0.037390205317288636\n",
      "Test Set Accuracy: 84.39\n",
      "\n",
      "Epoch: 45\n",
      "Train Set Loss: 0.036924358177632094\n",
      "Test Set Accuracy: 84.75\n",
      "\n",
      "Epoch: 46\n",
      "Train Set Loss: 0.036688906094133854\n",
      "Test Set Accuracy: 84.78\n",
      "\n",
      "Epoch: 47\n",
      "Train Set Loss: 0.03652169727616012\n",
      "Saving..\n",
      "Test Set Accuracy: 85.04\n",
      "\n",
      "Epoch: 48\n",
      "Train Set Loss: 0.03618277742251754\n",
      "Saving..\n",
      "Test Set Accuracy: 85.47\n",
      "\n",
      "Epoch: 49\n",
      "Train Set Loss: 0.03565346192106605\n",
      "Test Set Accuracy: 85.18\n",
      "\n",
      "Epoch: 50\n",
      "Train Set Loss: 0.035647349169552325\n",
      "Test Set Accuracy: 85.31\n",
      "\n",
      "Epoch: 51\n",
      "Train Set Loss: 0.03535126780733466\n",
      "Test Set Accuracy: 84.88\n",
      "\n",
      "Epoch: 52\n",
      "Train Set Loss: 0.03477174524277449\n",
      "Saving..\n",
      "Test Set Accuracy: 85.71\n",
      "\n",
      "Epoch: 53\n",
      "Train Set Loss: 0.03441815001085401\n",
      "Test Set Accuracy: 85.27\n",
      "\n",
      "Epoch: 54\n",
      "Train Set Loss: 0.03461835622176528\n",
      "Test Set Accuracy: 85.63\n",
      "\n",
      "Epoch: 55\n",
      "Train Set Loss: 0.03403878188207746\n",
      "Saving..\n",
      "Test Set Accuracy: 85.91\n",
      "\n",
      "Epoch: 56\n",
      "Train Set Loss: 0.03389089255958796\n",
      "Test Set Accuracy: 85.64\n",
      "\n",
      "Epoch: 57\n",
      "Train Set Loss: 0.03371512546852231\n",
      "Test Set Accuracy: 85.84\n",
      "\n",
      "Epoch: 58\n",
      "Train Set Loss: 0.033417165852412584\n",
      "Saving..\n",
      "Test Set Accuracy: 86.12\n",
      "\n",
      "Epoch: 59\n",
      "Train Set Loss: 0.032972260534390806\n",
      "Test Set Accuracy: 86.06\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 40  \n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+20):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoRGtBBaRF8g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3OJaGSsRGCp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8m0tUNP3QvhZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COW3YCVV2oNa",
    "outputId": "4a31f094-4823-4971-f7df-64c6d6dc6deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "Accuracy: 10.0\n",
      "Accuracy:  10.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',test(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkQa44cg2oUo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
