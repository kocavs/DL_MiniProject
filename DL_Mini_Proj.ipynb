{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kocavs/DL_MiniProject/blob/JD5226Branch/DL_Mini_Proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet For CIFAR0-10"
      ],
      "metadata": {
        "id": "5Cgn58bGLA7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My\\ Drive/DL_Mini_Proj\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzleoGvIa3JV",
        "outputId": "f354051a-e5aa-436f-e818-3558db18981e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/DL_Mini_Proj\n",
            "checkpoint  data  DL_Mini_Proj.ipynb  __pycache__  renet.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "#import renet\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "from torchsummary import summary\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "enCe4Ish2n47"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Construction"
      ],
      "metadata": {
        "id": "EgqUa4LeK3Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        # Branch 1: 1x1 convolution\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Branch 2: 1x1 convolution followed by 3x3 convolution\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1_out = self.branch1(x)\n",
        "        branch2_out = self.branch2(x)\n",
        "\n",
        "        return torch.cat([branch1_out, branch2_out], 1)\n",
        "\n",
        "class InceptionResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(InceptionResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(64, 64, 1)\n",
        "        self.layer2 = self._make_layer(128, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(256, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(512, 512, 1, stride=2)\n",
        "        \n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
        "        layers = []\n",
        "        for _ in range(num_blocks):\n",
        "            layers.append(InceptionModule(in_channels, out_channels))\n",
        "            in_channels = out_channels * 2\n",
        "\n",
        "        if stride == 2:\n",
        "            layers.append(nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Initialize the Inception-ResNet model"
      ],
      "metadata": {
        "id": "13PaS06K0N3g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = InceptionResNet(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "JZ5l09322n6z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f99yZ7-kNwN9",
        "outputId": "631eb00d-8800-4cec-cb71-3a4acda4dfd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]           4,160\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]           4,160\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "           Conv2d-11             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-12             [-1, 64, 8, 8]             128\n",
            "             ReLU-13             [-1, 64, 8, 8]               0\n",
            "  InceptionModule-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-16            [-1, 128, 8, 8]             256\n",
            "             ReLU-17            [-1, 128, 8, 8]               0\n",
            "           Conv2d-18            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
            "             ReLU-20            [-1, 128, 8, 8]               0\n",
            "           Conv2d-21            [-1, 128, 8, 8]         147,584\n",
            "      BatchNorm2d-22            [-1, 128, 8, 8]             256\n",
            "             ReLU-23            [-1, 128, 8, 8]               0\n",
            "  InceptionModule-24            [-1, 256, 8, 8]               0\n",
            "           Conv2d-25            [-1, 128, 8, 8]          32,896\n",
            "      BatchNorm2d-26            [-1, 128, 8, 8]             256\n",
            "             ReLU-27            [-1, 128, 8, 8]               0\n",
            "           Conv2d-28            [-1, 128, 8, 8]          32,896\n",
            "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
            "             ReLU-30            [-1, 128, 8, 8]               0\n",
            "           Conv2d-31            [-1, 128, 8, 8]         147,584\n",
            "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
            "             ReLU-33            [-1, 128, 8, 8]               0\n",
            "  InceptionModule-34            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-35            [-1, 256, 4, 4]               0\n",
            "           Conv2d-36            [-1, 256, 4, 4]          65,792\n",
            "      BatchNorm2d-37            [-1, 256, 4, 4]             512\n",
            "             ReLU-38            [-1, 256, 4, 4]               0\n",
            "           Conv2d-39            [-1, 256, 4, 4]          65,792\n",
            "      BatchNorm2d-40            [-1, 256, 4, 4]             512\n",
            "             ReLU-41            [-1, 256, 4, 4]               0\n",
            "           Conv2d-42            [-1, 256, 4, 4]         590,080\n",
            "      BatchNorm2d-43            [-1, 256, 4, 4]             512\n",
            "             ReLU-44            [-1, 256, 4, 4]               0\n",
            "  InceptionModule-45            [-1, 512, 4, 4]               0\n",
            "           Conv2d-46            [-1, 256, 4, 4]         131,328\n",
            "      BatchNorm2d-47            [-1, 256, 4, 4]             512\n",
            "             ReLU-48            [-1, 256, 4, 4]               0\n",
            "           Conv2d-49            [-1, 256, 4, 4]         131,328\n",
            "      BatchNorm2d-50            [-1, 256, 4, 4]             512\n",
            "             ReLU-51            [-1, 256, 4, 4]               0\n",
            "           Conv2d-52            [-1, 256, 4, 4]         590,080\n",
            "      BatchNorm2d-53            [-1, 256, 4, 4]             512\n",
            "             ReLU-54            [-1, 256, 4, 4]               0\n",
            "  InceptionModule-55            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-56            [-1, 512, 2, 2]               0\n",
            "           Conv2d-57            [-1, 512, 2, 2]         262,656\n",
            "      BatchNorm2d-58            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-59            [-1, 512, 2, 2]               0\n",
            "           Conv2d-60            [-1, 512, 2, 2]         262,656\n",
            "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-62            [-1, 512, 2, 2]               0\n",
            "           Conv2d-63            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-65            [-1, 512, 2, 2]               0\n",
            "  InceptionModule-66           [-1, 1024, 2, 2]               0\n",
            "        MaxPool2d-67           [-1, 1024, 1, 1]               0\n",
            "AdaptiveAvgPool2d-68           [-1, 1024, 1, 1]               0\n",
            "           Linear-69                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 4,926,666\n",
            "Trainable params: 4,926,666\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.05\n",
            "Params size (MB): 18.79\n",
            "Estimated Total Size (MB): 21.85\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construction Complete"
      ],
      "metadata": {
        "id": "P1F2LXoFL5K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "QwDtf6ypL-E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cutout(object):\n",
        "  \"\"\"Randomly mask out one or more patches from an image.\n",
        "  Args:\n",
        "      n_holes (int): Number of patches to cut out of each image.\n",
        "      length (int): The length (in pixels) of each square patch.\n",
        "  \"\"\"\n",
        "  def __init__(self, n_holes, length):\n",
        "      self.n_holes = n_holes\n",
        "      self.length = length\n",
        "\n",
        "  def __call__(self, img):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "          img (Tensor): Tensor image of size (C, H, W).\n",
        "      Returns:\n",
        "          Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "      \"\"\"\n",
        "      h = img.size(1)\n",
        "      w = img.size(2)\n",
        "\n",
        "      mask = np.ones((h, w), np.float32)\n",
        "\n",
        "      for n in range(self.n_holes):\n",
        "          y = np.random.randint(h)\n",
        "          x = np.random.randint(w)\n",
        "\n",
        "          y1 = np.clip(y - self.length // 2, 0, h)\n",
        "          y2 = np.clip(y + self.length // 2, 0, h)\n",
        "          x1 = np.clip(x - self.length // 2, 0, w)\n",
        "          x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "          mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "      mask = torch.from_numpy(mask)\n",
        "      mask = mask.expand_as(img)\n",
        "      img = img * mask\n",
        "\n",
        "      return img"
      ],
      "metadata": {
        "id": "TneJZzB8Jmqs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_CIFAR10(batch_size, train_ratio):\n",
        "\n",
        "  ROOT = './data'\n",
        "  trainset = torchvision.datasets.CIFAR10(\n",
        "      root = ROOT,\n",
        "      train = True, \n",
        "      download = True\n",
        "  )\n",
        "\n",
        "  # Compute means and standard deviations\n",
        "  means = trainset.data.mean(axis=(0,1,2)) / 255\n",
        "  stds = trainset.data.std(axis=(0,1,2)) / 255\n",
        "  #print(means, stds)\n",
        "\n",
        "  # Preprocess setting\n",
        "  transform_train = transforms.Compose([\n",
        "      transforms.RandomCrop(32, padding=4),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=means, std=stds),\n",
        "      Cutout(n_holes=1, length=16)\n",
        "  ])\n",
        "  transform_test = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=means, std=stds)\n",
        "  ])\n",
        "\n",
        "  # Load the dataset\n",
        "  trainset = torchvision.datasets.CIFAR10(\n",
        "      root = ROOT, \n",
        "      train = True, \n",
        "      download = True, \n",
        "      transform = transform_train\n",
        "  )\n",
        "  testset = torchvision.datasets.CIFAR10(\n",
        "      root = ROOT, \n",
        "      train = False, \n",
        "      download = True, \n",
        "      transform = transform_test\n",
        "  )\n",
        "\n",
        "  # Split trainset for validset\n",
        "  n_train = int(len(trainset) * train_ratio)\n",
        "  n_valid = len(trainset) - n_train\n",
        "  train_dataset, valid_dataset = data.random_split(trainset, [n_train, n_valid])\n",
        "  \n",
        "  # Build dataloader\n",
        "  train_iterator = data.DataLoader(train_dataset, batch_size)\n",
        "  valid_iterator = data.DataLoader(valid_dataset, batch_size)\n",
        "  test_iterator = data.DataLoader(testset, batch_size)\n",
        "\n",
        "  return train_iterator, valid_iterator, test_iterator"
      ],
      "metadata": {
        "id": "1DTMZC3WJmwF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader, validloader, testloader = load_CIFAR10(batch_size=16, train_ratio=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21PibWhZJ6da",
        "outputId": "59bbcbb6-0d17-456d-a582-1bda4396a7f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YcJteBmC2n8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "14de9aeb-348c-4a6d-d77d-570abc1318e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntransform_train = transforms.Compose([\\n    transforms.RandomCrop(32, padding=4),\\n    transforms.RandomHorizontalFlip(),\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n\\ntransform_test = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train) # change transform in future\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test) # change transform in future\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4HFVdimn2n-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "040a9c74-5ccc-444c-f6da-61ee205ef642"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrainset = torchvision.datasets.CIFAR10(\\n    root='./data', train=True, download=True, transform=transform_train) # change transform in future\\ntrainloader = torch.utils.data.DataLoader(\\n    trainset, batch_size=128, shuffle=True, num_workers=2)\\n\\ntestset = torchvision.datasets.CIFAR10(\\n    root='./data', train=False, download=True, transform=transform_test) # change transform in future\\ntestloader = torch.utils.data.DataLoader(\\n    testset, batch_size=100, shuffle=False, num_workers=2)\\n\\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\\n           'dog', 'frog', 'horse', 'ship', 'truck')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "metadata": {
        "id": "v6RvRO3e6Rjp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    print(\"Train Set Loss:\",train_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "JbBSkXWE2n_7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': model.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "    print('Test Set Accuracy:',acc)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "LxH7SkJJ2oBp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+20):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "pzs360FC2oKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277fd39b-550d-4515-9ad4-562563b5954d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "Train Set Loss: 6103.683391094208\n",
            "Saving..\n",
            "Test Set Accuracy: 39.93\n",
            "\n",
            "Epoch: 1\n",
            "Train Set Loss: 5039.246768653393\n",
            "Saving..\n",
            "Test Set Accuracy: 50.54\n",
            "\n",
            "Epoch: 2\n",
            "Train Set Loss: 4583.945307016373\n",
            "Saving..\n",
            "Test Set Accuracy: 57.0\n",
            "\n",
            "Epoch: 3\n",
            "Train Set Loss: 4137.669887006283\n",
            "Saving..\n",
            "Test Set Accuracy: 60.73\n",
            "\n",
            "Epoch: 4\n",
            "Train Set Loss: 3810.20165219903\n",
            "Saving..\n",
            "Test Set Accuracy: 64.71\n",
            "\n",
            "Epoch: 5\n",
            "Train Set Loss: 3542.352277368307\n",
            "Saving..\n",
            "Test Set Accuracy: 66.9\n",
            "\n",
            "Epoch: 6\n",
            "Train Set Loss: 3370.3911491036415\n",
            "Saving..\n",
            "Test Set Accuracy: 68.71\n",
            "\n",
            "Epoch: 7\n",
            "Train Set Loss: 3204.077872633934\n",
            "Saving..\n",
            "Test Set Accuracy: 70.33\n",
            "\n",
            "Epoch: 8\n",
            "Train Set Loss: 3067.4765536636114\n",
            "Saving..\n",
            "Test Set Accuracy: 73.74\n",
            "\n",
            "Epoch: 9\n",
            "Train Set Loss: 2963.851778358221\n",
            "Saving..\n",
            "Test Set Accuracy: 73.81\n",
            "\n",
            "Epoch: 10\n",
            "Train Set Loss: 2876.468645066023\n",
            "Saving..\n",
            "Test Set Accuracy: 73.96\n",
            "\n",
            "Epoch: 11\n",
            "Train Set Loss: 2764.154967099428\n",
            "Saving..\n",
            "Test Set Accuracy: 74.34\n",
            "\n",
            "Epoch: 12\n",
            "Train Set Loss: 2695.6585119366646\n",
            "Saving..\n",
            "Test Set Accuracy: 75.19\n",
            "\n",
            "Epoch: 13\n",
            "Train Set Loss: 2610.744331806898\n",
            "Saving..\n",
            "Test Set Accuracy: 77.73\n",
            "\n",
            "Epoch: 14\n",
            "Train Set Loss: 2549.3476837426424\n",
            "Test Set Accuracy: 77.6\n",
            "\n",
            "Epoch: 15\n",
            "Train Set Loss: 2478.611143618822\n",
            "Test Set Accuracy: 77.45\n",
            "\n",
            "Epoch: 16\n",
            "Train Set Loss: 2437.036105915904\n",
            "Saving..\n",
            "Test Set Accuracy: 79.65\n",
            "\n",
            "Epoch: 17\n",
            "Train Set Loss: 2383.419478431344\n",
            "Test Set Accuracy: 77.28\n",
            "\n",
            "Epoch: 18\n",
            "Train Set Loss: 2324.959626019001\n",
            "Test Set Accuracy: 79.59\n",
            "\n",
            "Epoch: 19\n",
            "Train Set Loss: 2286.217075407505\n",
            "Saving..\n",
            "Test Set Accuracy: 80.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for g in optimizer.param_groups:\n",
        "    print(optimizer.param_groups[0]['lr'])\n",
        "    g['lr'] = 0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XS9hEnaR0M2",
        "outputId": "fc73fd74-7af9-45dc-b6d4-c619e7dfc702"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.009755282581475762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 20  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+20):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulxHcGSzRFwn",
        "outputId": "140d6d9f-f9be-4959-ae88-99e5e72300f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 20\n",
            "Train Set Loss: 1608.802843336016\n",
            "Test Set Accuracy: 84.92\n",
            "\n",
            "Epoch: 21\n",
            "Train Set Loss: 1600.1520833522081\n",
            "Test Set Accuracy: 84.78\n",
            "\n",
            "Epoch: 22\n",
            "Train Set Loss: 1603.364780113101\n",
            "Saving..\n",
            "Test Set Accuracy: 85.25\n",
            "\n",
            "Epoch: 23\n",
            "Train Set Loss: 1588.7829240709543\n",
            "Test Set Accuracy: 84.84\n",
            "\n",
            "Epoch: 24\n",
            "Train Set Loss: 1568.23423044011\n",
            "Test Set Accuracy: 84.67\n",
            "\n",
            "Epoch: 25\n",
            "Train Set Loss: 1573.033382985741\n",
            "Test Set Accuracy: 85.03\n",
            "\n",
            "Epoch: 26\n",
            "Train Set Loss: 1551.8274260181934\n",
            "Test Set Accuracy: 85.06\n",
            "\n",
            "Epoch: 27\n",
            "Train Set Loss: 1550.0797832719982\n",
            "Test Set Accuracy: 84.81\n",
            "\n",
            "Epoch: 28\n",
            "Train Set Loss: 1532.4724542461336\n",
            "Test Set Accuracy: 85.0\n",
            "\n",
            "Epoch: 29\n",
            "Train Set Loss: 1534.7018443811685\n",
            "Test Set Accuracy: 85.04\n",
            "\n",
            "Epoch: 30\n",
            "Train Set Loss: 1527.4907198138535\n",
            "Saving..\n",
            "Test Set Accuracy: 85.49\n",
            "\n",
            "Epoch: 31\n",
            "Train Set Loss: 1529.2671598959714\n",
            "Test Set Accuracy: 85.42\n",
            "\n",
            "Epoch: 32\n",
            "Train Set Loss: 1498.2877764441073\n",
            "Test Set Accuracy: 85.29\n",
            "\n",
            "Epoch: 33\n",
            "Train Set Loss: 1524.1687925569713\n",
            "Test Set Accuracy: 85.38\n",
            "\n",
            "Epoch: 34\n",
            "Train Set Loss: 1509.602747309953\n",
            "Test Set Accuracy: 85.46\n",
            "\n",
            "Epoch: 35\n",
            "Train Set Loss: 1509.0300510190427\n",
            "Test Set Accuracy: 85.47\n",
            "\n",
            "Epoch: 36\n",
            "Train Set Loss: 1496.4604301415384\n",
            "Test Set Accuracy: 85.13\n",
            "\n",
            "Epoch: 37\n",
            "Train Set Loss: 1490.8240822069347\n",
            "Test Set Accuracy: 85.36\n",
            "\n",
            "Epoch: 38\n",
            "Train Set Loss: 1470.6754326988012\n",
            "Test Set Accuracy: 85.27\n",
            "\n",
            "Epoch: 39\n",
            "Train Set Loss: 1450.0468679480255\n",
            "Saving..\n",
            "Test Set Accuracy: 85.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QV9GS1HGRFyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lo0BGv5cRF39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9AFmB7xGRF6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zoRGtBBaRF8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3OJaGSsRGCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.param_groups[0]['lr'] # adam lr after 20 epoch -> 0.009755"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swnA-cyoQvc2",
        "outputId": "9111b108-19e3-48ed-df71-fae7d477212c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009755282581475762"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8m0tUNP3QvhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ',test(0))"
      ],
      "metadata": {
        "id": "COW3YCVV2oNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a31f094-4823-4971-f7df-64c6d6dc6deb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving..\n",
            "Accuracy: 10.0\n",
            "Accuracy:  10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkQa44cg2oUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}