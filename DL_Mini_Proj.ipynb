{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet For CIFAR0-10"
      ],
      "metadata": {
        "id": "5Cgn58bGLA7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "enCe4Ish2n47"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Construction"
      ],
      "metadata": {
        "id": "EgqUa4LeK3Tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use torch build of ResNet18"
      ],
      "metadata": {
        "id": "Zkp4v7ryLIWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = resnet18().to(device)"
      ],
      "metadata": {
        "id": "JZ5l09322n6z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 32, 232))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f99yZ7-kNwN9",
        "outputId": "d31d8f08-0a91-41c9-a775-3df2e0cfdb24"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 16, 116]           9,408\n",
            "       BatchNorm2d-2          [-1, 64, 16, 116]             128\n",
            "              ReLU-3          [-1, 64, 16, 116]               0\n",
            "         MaxPool2d-4            [-1, 64, 8, 58]               0\n",
            "            Conv2d-5            [-1, 64, 8, 58]          36,864\n",
            "       BatchNorm2d-6            [-1, 64, 8, 58]             128\n",
            "              ReLU-7            [-1, 64, 8, 58]               0\n",
            "            Conv2d-8            [-1, 64, 8, 58]          36,864\n",
            "       BatchNorm2d-9            [-1, 64, 8, 58]             128\n",
            "             ReLU-10            [-1, 64, 8, 58]               0\n",
            "       BasicBlock-11            [-1, 64, 8, 58]               0\n",
            "           Conv2d-12            [-1, 64, 8, 58]          36,864\n",
            "      BatchNorm2d-13            [-1, 64, 8, 58]             128\n",
            "             ReLU-14            [-1, 64, 8, 58]               0\n",
            "           Conv2d-15            [-1, 64, 8, 58]          36,864\n",
            "      BatchNorm2d-16            [-1, 64, 8, 58]             128\n",
            "             ReLU-17            [-1, 64, 8, 58]               0\n",
            "       BasicBlock-18            [-1, 64, 8, 58]               0\n",
            "           Conv2d-19           [-1, 128, 4, 29]          73,728\n",
            "      BatchNorm2d-20           [-1, 128, 4, 29]             256\n",
            "             ReLU-21           [-1, 128, 4, 29]               0\n",
            "           Conv2d-22           [-1, 128, 4, 29]         147,456\n",
            "      BatchNorm2d-23           [-1, 128, 4, 29]             256\n",
            "           Conv2d-24           [-1, 128, 4, 29]           8,192\n",
            "      BatchNorm2d-25           [-1, 128, 4, 29]             256\n",
            "             ReLU-26           [-1, 128, 4, 29]               0\n",
            "       BasicBlock-27           [-1, 128, 4, 29]               0\n",
            "           Conv2d-28           [-1, 128, 4, 29]         147,456\n",
            "      BatchNorm2d-29           [-1, 128, 4, 29]             256\n",
            "             ReLU-30           [-1, 128, 4, 29]               0\n",
            "           Conv2d-31           [-1, 128, 4, 29]         147,456\n",
            "      BatchNorm2d-32           [-1, 128, 4, 29]             256\n",
            "             ReLU-33           [-1, 128, 4, 29]               0\n",
            "       BasicBlock-34           [-1, 128, 4, 29]               0\n",
            "           Conv2d-35           [-1, 256, 2, 15]         294,912\n",
            "      BatchNorm2d-36           [-1, 256, 2, 15]             512\n",
            "             ReLU-37           [-1, 256, 2, 15]               0\n",
            "           Conv2d-38           [-1, 256, 2, 15]         589,824\n",
            "      BatchNorm2d-39           [-1, 256, 2, 15]             512\n",
            "           Conv2d-40           [-1, 256, 2, 15]          32,768\n",
            "      BatchNorm2d-41           [-1, 256, 2, 15]             512\n",
            "             ReLU-42           [-1, 256, 2, 15]               0\n",
            "       BasicBlock-43           [-1, 256, 2, 15]               0\n",
            "           Conv2d-44           [-1, 256, 2, 15]         589,824\n",
            "      BatchNorm2d-45           [-1, 256, 2, 15]             512\n",
            "             ReLU-46           [-1, 256, 2, 15]               0\n",
            "           Conv2d-47           [-1, 256, 2, 15]         589,824\n",
            "      BatchNorm2d-48           [-1, 256, 2, 15]             512\n",
            "             ReLU-49           [-1, 256, 2, 15]               0\n",
            "       BasicBlock-50           [-1, 256, 2, 15]               0\n",
            "           Conv2d-51            [-1, 512, 1, 8]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 8]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 8]               0\n",
            "           Conv2d-54            [-1, 512, 1, 8]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 8]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 8]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 8]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 8]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 8]               0\n",
            "           Conv2d-60            [-1, 512, 1, 8]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 8]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 8]               0\n",
            "           Conv2d-63            [-1, 512, 1, 8]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 8]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 8]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 8]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 9.38\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 54.06\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construction Complete"
      ],
      "metadata": {
        "id": "P1F2LXoFL5K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "QwDtf6ypL-E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform_train = transforms.Compose([\n",
        "    #transforms.RandomCrop(32, padding=4),\n",
        "    #transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n"
      ],
      "metadata": {
        "id": "YcJteBmC2n8b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train) # change transform in future\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test) # change transform in future\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "4HFVdimn2n-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c864087d-2155-4196-e106-db0a1ae5620b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1,\n",
        "                       weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
      ],
      "metadata": {
        "id": "v6RvRO3e6Rjp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n"
      ],
      "metadata": {
        "id": "JbBSkXWE2n_7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': model.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "LxH7SkJJ2oBp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "pzs360FC2oKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66842a14-6429-4a19-e85c-004a889c8e30"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Epoch: 4\n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "Epoch: 8\n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            "\n",
            "Epoch: 10\n",
            "\n",
            "Epoch: 11\n",
            "\n",
            "Epoch: 12\n",
            "\n",
            "Epoch: 13\n",
            "\n",
            "Epoch: 14\n",
            "\n",
            "Epoch: 15\n",
            "\n",
            "Epoch: 16\n",
            "\n",
            "Epoch: 17\n",
            "\n",
            "Epoch: 18\n",
            "\n",
            "Epoch: 19\n",
            "\n",
            "Epoch: 20\n",
            "\n",
            "Epoch: 21\n",
            "\n",
            "Epoch: 22\n",
            "\n",
            "Epoch: 23\n",
            "\n",
            "Epoch: 24\n",
            "\n",
            "Epoch: 25\n",
            "\n",
            "Epoch: 26\n",
            "\n",
            "Epoch: 27\n",
            "\n",
            "Epoch: 28\n",
            "\n",
            "Epoch: 29\n",
            "\n",
            "Epoch: 30\n",
            "\n",
            "Epoch: 31\n",
            "\n",
            "Epoch: 32\n",
            "\n",
            "Epoch: 33\n",
            "\n",
            "Epoch: 34\n",
            "\n",
            "Epoch: 35\n",
            "\n",
            "Epoch: 36\n",
            "\n",
            "Epoch: 37\n",
            "\n",
            "Epoch: 38\n",
            "\n",
            "Epoch: 39\n",
            "\n",
            "Epoch: 40\n",
            "\n",
            "Epoch: 41\n",
            "\n",
            "Epoch: 42\n",
            "\n",
            "Epoch: 43\n",
            "\n",
            "Epoch: 44\n",
            "\n",
            "Epoch: 45\n",
            "\n",
            "Epoch: 46\n",
            "\n",
            "Epoch: 47\n",
            "\n",
            "Epoch: 48\n",
            "\n",
            "Epoch: 49\n",
            "\n",
            "Epoch: 50\n",
            "\n",
            "Epoch: 51\n",
            "\n",
            "Epoch: 52\n",
            "\n",
            "Epoch: 53\n",
            "\n",
            "Epoch: 54\n",
            "\n",
            "Epoch: 55\n",
            "\n",
            "Epoch: 56\n",
            "\n",
            "Epoch: 57\n",
            "\n",
            "Epoch: 58\n",
            "\n",
            "Epoch: 59\n",
            "\n",
            "Epoch: 60\n",
            "\n",
            "Epoch: 61\n",
            "\n",
            "Epoch: 62\n",
            "\n",
            "Epoch: 63\n",
            "\n",
            "Epoch: 64\n",
            "\n",
            "Epoch: 65\n",
            "\n",
            "Epoch: 66\n",
            "\n",
            "Epoch: 67\n",
            "\n",
            "Epoch: 68\n",
            "\n",
            "Epoch: 69\n",
            "\n",
            "Epoch: 70\n",
            "\n",
            "Epoch: 71\n",
            "\n",
            "Epoch: 72\n",
            "\n",
            "Epoch: 73\n",
            "\n",
            "Epoch: 74\n",
            "\n",
            "Epoch: 75\n",
            "\n",
            "Epoch: 76\n",
            "\n",
            "Epoch: 77\n",
            "\n",
            "Epoch: 78\n",
            "\n",
            "Epoch: 79\n",
            "\n",
            "Epoch: 80\n",
            "\n",
            "Epoch: 81\n",
            "\n",
            "Epoch: 82\n",
            "\n",
            "Epoch: 83\n",
            "\n",
            "Epoch: 84\n",
            "\n",
            "Epoch: 85\n",
            "\n",
            "Epoch: 86\n",
            "\n",
            "Epoch: 87\n",
            "\n",
            "Epoch: 88\n",
            "\n",
            "Epoch: 89\n",
            "Saving..\n",
            "\n",
            "Epoch: 90\n",
            "\n",
            "Epoch: 91\n",
            "\n",
            "Epoch: 92\n",
            "\n",
            "Epoch: 93\n",
            "\n",
            "Epoch: 94\n",
            "\n",
            "Epoch: 95\n",
            "\n",
            "Epoch: 96\n",
            "\n",
            "Epoch: 97\n",
            "\n",
            "Epoch: 98\n",
            "\n",
            "Epoch: 99\n",
            "\n",
            "Epoch: 100\n",
            "\n",
            "Epoch: 101\n",
            "\n",
            "Epoch: 102\n",
            "\n",
            "Epoch: 103\n",
            "\n",
            "Epoch: 104\n",
            "\n",
            "Epoch: 105\n",
            "\n",
            "Epoch: 106\n",
            "\n",
            "Epoch: 107\n",
            "Saving..\n",
            "\n",
            "Epoch: 108\n",
            "\n",
            "Epoch: 109\n",
            "\n",
            "Epoch: 110\n",
            "\n",
            "Epoch: 111\n",
            "Saving..\n",
            "\n",
            "Epoch: 112\n",
            "\n",
            "Epoch: 113\n",
            "Saving..\n",
            "\n",
            "Epoch: 114\n",
            "\n",
            "Epoch: 115\n",
            "\n",
            "Epoch: 116\n",
            "\n",
            "Epoch: 117\n",
            "\n",
            "Epoch: 118\n",
            "Saving..\n",
            "\n",
            "Epoch: 119\n",
            "\n",
            "Epoch: 120\n",
            "\n",
            "Epoch: 121\n",
            "\n",
            "Epoch: 122\n",
            "\n",
            "Epoch: 123\n",
            "\n",
            "Epoch: 124\n",
            "\n",
            "Epoch: 125\n",
            "\n",
            "Epoch: 126\n",
            "\n",
            "Epoch: 127\n",
            "\n",
            "Epoch: 128\n",
            "\n",
            "Epoch: 129\n",
            "\n",
            "Epoch: 130\n",
            "\n",
            "Epoch: 131\n",
            "Saving..\n",
            "\n",
            "Epoch: 132\n",
            "\n",
            "Epoch: 133\n",
            "\n",
            "Epoch: 134\n",
            "Saving..\n",
            "\n",
            "Epoch: 135\n",
            "\n",
            "Epoch: 136\n",
            "\n",
            "Epoch: 137\n",
            "\n",
            "Epoch: 138\n",
            "\n",
            "Epoch: 139\n",
            "\n",
            "Epoch: 140\n",
            "\n",
            "Epoch: 141\n",
            "\n",
            "Epoch: 142\n",
            "\n",
            "Epoch: 143\n",
            "\n",
            "Epoch: 144\n",
            "\n",
            "Epoch: 145\n",
            "\n",
            "Epoch: 146\n",
            "\n",
            "Epoch: 147\n",
            "\n",
            "Epoch: 148\n",
            "\n",
            "Epoch: 149\n",
            "\n",
            "Epoch: 150\n",
            "\n",
            "Epoch: 151\n",
            "\n",
            "Epoch: 152\n",
            "\n",
            "Epoch: 153\n",
            "\n",
            "Epoch: 154\n",
            "Saving..\n",
            "\n",
            "Epoch: 155\n",
            "\n",
            "Epoch: 156\n",
            "\n",
            "Epoch: 157\n",
            "\n",
            "Epoch: 158\n",
            "\n",
            "Epoch: 159\n",
            "\n",
            "Epoch: 160\n",
            "\n",
            "Epoch: 161\n",
            "\n",
            "Epoch: 162\n",
            "Saving..\n",
            "\n",
            "Epoch: 163\n",
            "\n",
            "Epoch: 164\n",
            "\n",
            "Epoch: 165\n",
            "\n",
            "Epoch: 166\n",
            "\n",
            "Epoch: 167\n",
            "\n",
            "Epoch: 168\n",
            "\n",
            "Epoch: 169\n",
            "Saving..\n",
            "\n",
            "Epoch: 170\n",
            "Saving..\n",
            "\n",
            "Epoch: 171\n",
            "\n",
            "Epoch: 172\n",
            "\n",
            "Epoch: 173\n",
            "\n",
            "Epoch: 174\n",
            "Saving..\n",
            "\n",
            "Epoch: 175\n",
            "\n",
            "Epoch: 176\n",
            "\n",
            "Epoch: 177\n",
            "\n",
            "Epoch: 178\n",
            "Saving..\n",
            "\n",
            "Epoch: 179\n",
            "\n",
            "Epoch: 180\n",
            "Saving..\n",
            "\n",
            "Epoch: 181\n",
            "\n",
            "Epoch: 182\n",
            "\n",
            "Epoch: 183\n",
            "Saving..\n",
            "\n",
            "Epoch: 184\n",
            "Saving..\n",
            "\n",
            "Epoch: 185\n",
            "Saving..\n",
            "\n",
            "Epoch: 186\n",
            "Saving..\n",
            "\n",
            "Epoch: 187\n",
            "\n",
            "Epoch: 188\n",
            "Saving..\n",
            "\n",
            "Epoch: 189\n",
            "\n",
            "Epoch: 190\n",
            "Saving..\n",
            "\n",
            "Epoch: 191\n",
            "\n",
            "Epoch: 192\n",
            "Saving..\n",
            "\n",
            "Epoch: 193\n",
            "Saving..\n",
            "\n",
            "Epoch: 194\n",
            "\n",
            "Epoch: 195\n",
            "\n",
            "Epoch: 196\n",
            "Saving..\n",
            "\n",
            "Epoch: 197\n",
            "\n",
            "Epoch: 198\n",
            "\n",
            "Epoch: 199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ',test(0))"
      ],
      "metadata": {
        "id": "COW3YCVV2oNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f328d6d-d690-4796-ed16-74980cf785a8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ogl6KO_2oPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EBvyS3ut2oRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2Qnj8yv2oTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkQa44cg2oUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}