{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "xIMaBnQadKbg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cutout(object):\n",
        "  \"\"\"Randomly mask out one or more patches from an image.\n",
        "  Args:\n",
        "      n_holes (int): Number of patches to cut out of each image.\n",
        "      length (int): The length (in pixels) of each square patch.\n",
        "  \"\"\"\n",
        "  def __init__(self, n_holes, length):\n",
        "      self.n_holes = n_holes\n",
        "      self.length = length\n",
        "\n",
        "  def __call__(self, img):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "          img (Tensor): Tensor image of size (C, H, W).\n",
        "      Returns:\n",
        "          Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "      \"\"\"\n",
        "      h = img.size(1)\n",
        "      w = img.size(2)\n",
        "\n",
        "      mask = np.ones((h, w), np.float32)\n",
        "\n",
        "      for n in range(self.n_holes):\n",
        "          y = np.random.randint(h)\n",
        "          x = np.random.randint(w)\n",
        "\n",
        "          y1 = np.clip(y - self.length // 2, 0, h)\n",
        "          y2 = np.clip(y + self.length // 2, 0, h)\n",
        "          x1 = np.clip(x - self.length // 2, 0, w)\n",
        "          x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "          mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "      mask = torch.from_numpy(mask)\n",
        "      mask = mask.expand_as(img)\n",
        "      img = img * mask\n",
        "\n",
        "      return img"
      ],
      "metadata": {
        "id": "_oa2s1mo4Vm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "dfQhqnFMZLVn"
      },
      "outputs": [],
      "source": [
        "def load_CIFAR10(batch_size, train_ratio):\n",
        "\n",
        "  ROOT = './data'\n",
        "  trainset = torchvision.datasets.CIFAR10(\n",
        "      root = ROOT,\n",
        "      train = True, \n",
        "      download = True\n",
        "  )\n",
        "\n",
        "  # Compute means and standard deviations\n",
        "  means = trainset.data.mean(axis=(0,1,2)) / 255\n",
        "  stds = trainset.data.std(axis=(0,1,2)) / 255\n",
        "  #print(means, stds)\n",
        "\n",
        "  # Preprocess setting\n",
        "  transform_train = transforms.Compose([\n",
        "      transforms.RandomCrop(32, padding=4),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=means, std=stds),\n",
        "      Cutout(n_holes=1, length=16)\n",
        "  ])\n",
        "  transform_test = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=means, std=stds)\n",
        "  ])\n",
        "\n",
        "  # Load the dataset\n",
        "  trainset = torchvision.datasets.CIFAR10(\n",
        "      root = ROOT, \n",
        "      train = True, \n",
        "      download = True, \n",
        "      transform = transform_train\n",
        "  )\n",
        "  testset = torchvision.datasets.CIFAR10(\n",
        "      root = ROOT, \n",
        "      train = False, \n",
        "      download = True, \n",
        "      transform = transform_test\n",
        "  )\n",
        "\n",
        "  # Split trainset for validset\n",
        "  n_train = int(len(trainset) * train_ratio)\n",
        "  n_valid = len(trainset) - n_train\n",
        "  train_dataset, valid_dataset = data.random_split(trainset, [n_train, n_valid])\n",
        "  \n",
        "  # Build dataloader\n",
        "  train_iterator = data.DataLoader(train_dataset, batch_size)\n",
        "  valid_iterator = data.DataLoader(valid_dataset, batch_size)\n",
        "  test_iterator = data.DataLoader(testset, batch_size)\n",
        "\n",
        "  return train_iterator, valid_iterator, test_iterator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoader, validLoader, testLoader = load_CIFAR10(batch_size=16, train_ratio=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q365aQ4CvTcc",
        "outputId": "9e3bfb10-dc1b-4ee8-e129-2c05bd76ec50"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainLoader))\n",
        "print(len(validLoader))\n",
        "print(len(testLoader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDn-iZLawLrT",
        "outputId": "b688d508-411c-470c-ec94-1238797e30c7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3125\n",
            "0\n",
            "625\n"
          ]
        }
      ]
    }
  ]
}